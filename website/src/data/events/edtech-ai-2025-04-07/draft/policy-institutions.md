# AI in Education and EdTech Roundtable - April 2025

In April 2025, a roundtable of 40+ educators, EdTech executives, AI experts, and academic leaders convened in Boston under the Chatham House Rule to discuss how AI is changing education. The following document synthesizes insights from that event with recent academic research (2022–2025) and conference proceedings, offering guidance for educational leaders and institutions.

> *AI Usage Statement*
> This paper was generated using AI at several stages. First, we used AI to transcribe handwritten notes. Then we combined the notes with the moderator guides and questions and used AI to expand on the notes, filling in gaps and interpolating difficult to read or understand notes. These were human reviewed and edited. Next, we used AI to generate a summary of the discussion, which was also human revieed and edited. Based on the notes and summary we used deep research models to build this policy document. These are currently in the process of getting human reviewed and validated.

## Policy Paper for Education Leaders (Institutions)

### Overview and Context 
Educational institutions face a pivotal moment as artificial intelligence rapidly advances. Leaders are grappling with "more questions than answers," with the sector still defining problem statements as much as solutions[1]. Rapid technological developments in AI have outpaced many policy and practice frameworks[2], leaving school and university leaders to navigate tremendous uncertainty. At the same time, human connection and mentorship remain **non-negotiable** core values in education[3]. This policy paper outlines how institutional leaders can set priorities, implement AI thoughtfully, and uphold ethical standards to ensure AI serves to enhance – not replace – human-centered learning.

### Strategic Priorities for AI Integration 
**Clarify Educational Purpose in an AI Age:** As AI capabilities expand, educational institutions must **redefine their purpose** – identifying which learning experiences should remain uniquely human-centered and which can be enhanced by technology[4]. For example, routine knowledge delivery may be automated by AI tutors, but cultivating critical thinking, creativity, and social-emotional skills should be foregrounded. Recent research emphasizes that skills like creativity, collaboration, and ethical judgment are increasing in importance as routine information processing is offloaded to AI[5]. Leaders should articulate a vision of education where AI supports the mission (e.g. personalized tutoring or analytics) without undermining the development of human traits such as curiosity and empathy.

**Focus on Human Connection and Teacher Roles:** The roundtable reaffirmed that "humans need connection" and effective education will continue to rely on relationships[6][7]. In practice, this means prioritizing **connection over automation** in AI deployments. For instance, AI tools might take over tedious grading or scheduling tasks, freeing teachers to spend more one-on-one time with students. The U.S. Department of Education similarly recommends a *"human-in-the-loop"* approach – envisioning AI as an *assistive electric bike* (amplifying human effort) rather than an autonomous robot vacuum that replaces human involvement[8][9]. Faculty should be supported to evolve from lecturers into facilitators and coaches, aided (but not supplanted) by AI. At the Stanford **Accelerate EdTech** summit, experts agreed that successful innovation "puts educators in the driver's seat" – the best edtech empowers teachers rather than complicating their jobs[10]. When teachers understand an AI tool deeply and have agency in its use, they often discover creative educational applications beyond what developers imagined[11]. Leaders should therefore invest in professional development so that teachers become confident AI users, able to harness new tools to enhance student engagement while maintaining the *human touch* in learning.

**Champion Equity and Inclusion:** A widening AI adoption gap is emerging in education – early adopters forge ahead while others feel left behind[12]. Without intentional action, AI could exacerbate disparities. Leaders must make equity a cornerstone of their AI strategy, ensuring all students and educators benefit. UNESCO warns that AI in education sits at an inflection point: it could either increase disparities or shrink them, "depending on what we do now"[13]. Recent surveys show uneven AI adoption: in 2023–24 only about 25% of K-12 teachers in the U.S. had used AI for instruction, and schools in high-poverty communities were significantly **less likely** to use AI tools than those in low-poverty communities[14]. This digital divide demands leadership attention. Institutional plans should address infrastructure and training gaps in under-resourced schools, to "leave no one behind." The 2023 International Conference on AI in Education (AIED) echoed this priority by calling for AI to provide *"inclusive and equitable quality education"* for all learners[15]. Education leaders should set targets to broaden access – for example, providing AI literacy programs for both staff and students, and investing in tools that accommodate learners with disabilities or different language backgrounds. In short, **equity** should be a KPI for any AI initiative.

**Align AI with Institutional Mission:** Rather than adopting AI for its own sake or due to hype, leaders should evaluate how each AI application serves their educational mission. This involves cross-functional strategic planning. Guiding questions include: *Will this AI tool improve student learning outcomes or wellbeing? Does it align with our pedagogical values?* For instance, a university might explore AI to personalize learning paths, but also ensure it aligns with the institution's commitment to student agency and privacy. Multiple roundtable tables noted a strategic tension around **data ownership** – who owns learner data and AI-generated insights?[16] Leaders must establish policies so that AI vendors do not exploit student data, and that learners' rights are protected. In setting AI strategy, it's recommended to involve diverse stakeholders (faculty, IT, students, community) to map both opportunities and "known-unknowns"[17]. By openly acknowledging uncertainties, leaders can foster a culture of trust and learning as they experiment with AI.

### Implementation Guidance for Institutions  
**Phased and Participatory Adoption:** Given the fast pace of AI, a careful sequencing of adoption is prudent. A key recommendation from the roundtable was to **"run dual roadmaps"** – one experimental sandbox for rapid trials and one core track for measured, validated implementations[18]. Early adopter faculty or departments can pilot new AI tools in a sandbox environment, generating insights and best practices. Meanwhile, mainstream adoption should follow only after evidence of value and reliability is established. This two-speed approach prevents the institution from either falling behind or rushing in blindly. For example, a college might quickly pilot an AI tutoring system in a few classes (to learn its effects) while holding off on campus-wide deployment until it's proven and faculty are trained. Education leaders should also create **forums for dialogue** where AI enthusiasts, skeptics, and late adopters can share experiences[19]. This "leveling of the conversation" helps surface concerns and temper the early-adopter echo chamber.

**Invest in Capacity Building:** Implementing AI in schools and universities requires new capacities. Leaders should budget for ongoing **professional development** on AI tools and data literacy. Frontline educators need time to learn and tinker with AI (with technical support available) to integrate it effectively into curricula. According to a RAND study, while most U.S. school districts in 2023 planned to train teachers on AI, *very few had actually crafted guidance* on AI use[20]. This highlights a gap: leaders should not only offer training but also clear guidelines for classroom AI use (e.g. academic integrity policies for generative AI, or protocols for AI-driven personalized learning). Some early-adopter districts have begun creating AI **"readiness checklists"** and policies to guide teachers[21]. Leveraging such resources and adapting them to local context can jump-start a school's AI readiness.

**Pilot and Evaluate ROI on Learning:** In terms of return on investment, leaders should demand evidence of learning benefits, not just novelty. Small-scale pilots with rigorous evaluation can determine if an AI application actually improves student outcomes or operational efficiency. For instance, an AI writing assistant might be piloted to see if it enhances student writing skills *and* maintains academic honesty standards. It's important to go beyond vendor claims – partner with researchers if possible to measure impacts. The ethos should be *"use AI to enhance education, not just for the sake of AI."* One CEO at the roundtable noted that **data quality trumps data volume** for driving value[22] – a reminder that AI without good data and clear pedagogical purpose will disappoint. Leaders should identify high-value use cases (e.g. AI for early warning in student support, or intelligent tutoring in math remediation) aligned to strategic goals, and concentrate efforts there.

**Infrastructure and IT Governance:** Adopting AI may strain or require upgrades to institutional infrastructure. Leaders should work with CIOs to ensure computing resources, network bandwidth, and data storage comply with the needs of AI applications (especially those using large models or real-time analytics). Crucially, **data privacy and security** measures must be updated. Many existing student data privacy policies (FERPA, state laws, etc.) need reinterpretation in light of AI[23]. Leaders should audit how AI tools handle student data: Is data encrypted? Where is it stored? Who can access it? As a best practice, form an AI governance committee or task force that includes legal, ethics, and cybersecurity expertise to review any AI-enabled product before adoption. This committee can vet tools for compliance with privacy laws and alignment with ethical standards (e.g. checking for algorithmic bias). Proactively establishing governance will help institutions avoid reactive scandals or violations later.

### Ethical and Policy Considerations 
**Address Bias and Fairness:** AI systems can inadvertently perpetuate biases present in training data. In an educational context, this could mean an adaptive learning system that unfairly favors certain linguistic or cultural backgrounds, or an AI predictive tool that labels students from marginalized groups as "at risk" based on skewed data. Education leaders must demand transparency from AI vendors about how models were trained and tested for bias. As the roundtable highlighted, stronger **ethical frameworks** are needed to govern AI in schools[24]. Leaders should adopt principles akin to an "AI ethics policy" – for example, requiring any AI used for high-stakes decisions (like grading or admissions) to be explainable and to include human review. Some institutions are creating ethics review boards to evaluate AI research and tools on campus. In practice, **human oversight** should be maintained on any automated decisions that impact student opportunities or wellbeing[25][26]. Also, including diverse voices (teachers, students, parents) in evaluating AI tools can help catch biases or cultural blind spots early.

**Data Privacy and Ownership:** With AI systems hungry for data, questions arise about who owns educational data and how it's used. Leaders should institute clear data governance policies. For example, if an edtech AI platform uses student interaction data to improve its algorithm, the institution should ensure that data is anonymized and that students/parents have given informed consent where required. Regulations like FERPA and COPPA already provide baselines[27], but many were written before AI and may need updating or stricter enforcement. The policy gap was noted at the roundtable: *"policy, ethics & equitable access are lagging the tech curve."*[28]. Until regulators catch up, institutional leaders have a responsibility to set local guardrails. A sensible step is to conduct Privacy Impact Assessments for new AI tools and to be transparent with the community about what student data is collected and analyzed. Additionally, leaders might lobby for or contribute to developing **education-specific AI guidelines** in their region, as a collective approach to these challenges will be more effective than each institution acting alone[29][30].

**Preventing Misuse and Preserving Academic Integrity:** The surge of generative AI (like AI writing assistants or coding helpers) brings benefits and new dilemmas. School leaders should lead conversations on academic integrity – e.g. updating honor codes to clarify how AI can or cannot be used on assignments[31]. Instead of outright bans, some universities are shifting to assessments that emphasize oral exams, presentations, or in-class work where AI use is limited, thereby "designing out" easy AI cheating. K-12 superintendents, meanwhile, are considering policies for AI chatbot use in classrooms, balancing innovation with the need to maintain student skill development (e.g., ensuring students can still write independently). It's also vital to guide students on *ethical AI use*: just as we teach citation of sources, we should teach when and how to credit AI assistance. Education leaders could implement AI literacy modules that include ethics, helping students become responsible AI users and creators[32]. By instilling these values, institutions prepare learners for a workforce where AI will be ubiquitous, and personal integrity in its use will be paramount.

**Monitoring Impact on Wellbeing:** Rapid AI-driven change can cause stress for staff and students. Leaders should be attentive to signs of **burnout** or "AI overload" in their communities. Early adopters may face "tool fatigue" from trying every new AI gadget[33], while others feel anxiety about keeping up. One takeaway for leaders is to explicitly *monitor burnout* as a metric[34]. This could mean adding teacher well-being surveys focusing on workload impact of EdTech, or capping the number of new tools introduced per semester. Setting reasonable pacing of innovation is an ethical leadership act: as one discussion noted, there's no value in adopting a new AI tool "that will be obsolete in 6 months" if it burns out your faculty in the process[35]. Maintaining a healthy pace of change, providing mental health resources, and fostering peer support (like mentorship between tech-savvy and less tech-savvy teachers) all help create a sustainable environment for innovation.

### Recommendations for Education Leaders 
- **Lead with Vision and Communication:** Develop a clear AI vision tied to your educational mission and communicate it to all stakeholders. Acknowledge the unknowns openly[36] and invite input to build trust as you navigate the AI journey together.  
- **Empower Educators:** Invest in training and give teachers agency in AI adoption. Focus on tools that save time (e.g. automate grading) so teachers can strengthen human relationships with students[37][38]. Involve educators in selecting and evaluating AI – those on the ground will ensure the tech is actually useful in practice.  
- **Adopt Slowly, Evaluate Continuously:** Use pilot programs and dual roadmaps[39] to balance innovation and caution. Gather data on what works, and scale up deliberately. Continuously assess the impact on student learning and educator workload, and be willing to pause or roll back if an AI tool isn't delivering benefits.  
- **Prioritize Equity:** Proactively support under-resourced schools, departments, or learner groups in AI adoption. For instance, ensure high-poverty schools in your district receive extra support and funding for AI initiatives, to counteract existing disparities[40][41]. Consider accessibility – e.g. AI tools that work for students with disabilities or multilingual learners – and involve community voices when deploying AI programs.  
- **Strengthen Ethical Governance:** Update data privacy policies and create an AI ethics framework at your institution. Require human oversight for critical decisions[42], demand transparency from vendors, and set up review boards or committees to vet AI implementations. By leading on policy at the local level, education leaders fill the current vacuum and model responsible AI use[43]. 

By taking these steps, education leaders can harness AI's potential for personalized learning and operational efficiency **while keeping humans at the center of education** – ensuring technology serves as a tool to advance the institution's mission, not an end in itself.

---

## Endnotes

1. "Leaders are grappling with 'more questions than answers,' with the sector still defining problem statements as much as solutions."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

2. "Rapid technological developments in AI have outpaced many policy and practice frameworks."  
*UNESCO International Policy Frameworks*  
https://www.unesco.org/en/digital-education/artificial-intelligence

3. "Human connection and mentorship remain non-negotiable core values in education."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

4. "Educational institutions must redefine their purpose – identifying which learning experiences should remain uniquely human-centered and which can be enhanced by technology."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

5. "Recent research emphasizes that skills like creativity, collaboration, and ethical judgment are increasing in importance as routine information processing is offloaded to AI."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

6. "The roundtable reaffirmed that 'humans need connection' and effective education will continue to rely on relationships."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

7. "Effective education will continue to rely on relationships."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

8. "The U.S. Department of Education recommends a 'human-in-the-loop' approach – envisioning AI as an assistive electric bike (amplifying human effort) rather than an autonomous robot vacuum that replaces human involvement."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

9. "AI as an assistive electric bike (amplifying human effort) rather than an autonomous robot vacuum that replaces human involvement."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

10. "At the Stanford Accelerate EdTech summit, experts agreed that successful innovation 'puts educators in the driver's seat' – the best edtech empowers teachers rather than complicating their jobs."  
*Stanford Summit 2024*  
https://ed.stanford.edu/events/accelerate-edtech-summit-2024

11. "When teachers understand an AI tool deeply and have agency in its use, they often discover creative educational applications beyond what developers imagined."  
*Stanford Summit 2024*  
https://ed.stanford.edu/events/accelerate-edtech-summit-2024

12. "A widening AI adoption gap is emerging in education – early adopters forge ahead while others feel left behind."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

13. "UNESCO warns that AI in education sits at an inflection point: it could either increase disparities or shrink them, 'depending on what we do now'."  
*UNESCO International Policy Frameworks*  
https://www.unesco.org/en/digital-education/artificial-intelligence

14. "Recent surveys show uneven AI adoption: in 2023–24 only about 25% of K-12 teachers in the U.S. had used AI for instruction, and schools in high-poverty communities were significantly less likely to use AI tools than those in low-poverty communities."  
*RAND Study 2023*  
https://www.rand.org/pubs/research_reports/RRA134-25.html

15. "The 2023 International Conference on AI in Education (AIED) echoed this priority by calling for AI to provide 'inclusive and equitable quality education' for all learners."  
*AIED 2023*  
https://aied.org/aied2023/

16. "Multiple roundtable tables noted a strategic tension around data ownership – who owns learner data and AI-generated insights?"  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

17. "In setting AI strategy, it's recommended to involve diverse stakeholders (faculty, IT, students, community) to map both opportunities and 'known-unknowns'."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

18. "A key recommendation from the roundtable was to 'run dual roadmaps' – one experimental sandbox for rapid trials and one core track for measured, validated implementations."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

19. "Education leaders should also create forums for dialogue where AI enthusiasts, skeptics, and late adopters can share experiences."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

20. "According to a RAND study, while most U.S. school districts in 2023 planned to train teachers on AI, very few had actually crafted guidance on AI use."  
*RAND Study 2023*  
https://www.rand.org/pubs/research_reports/RRA134-25.html

21. "Some early-adopter districts have begun creating AI 'readiness checklists' and policies to guide teachers."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

22. "One CEO at the roundtable noted that data quality trumps data volume for driving value."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

23. "Many existing student data privacy policies (FERPA, state laws, etc.) need reinterpretation in light of AI."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

24. "As the roundtable highlighted, stronger ethical frameworks are needed to govern AI in schools."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

25. "In practice, human oversight should be maintained on any automated decisions that impact student opportunities or wellbeing."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

26. "Human oversight should be maintained on any automated decisions that impact student opportunities or wellbeing."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

27. "Regulations like FERPA and COPPA already provide baselines, but many were written before AI and may need updating or stricter enforcement."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

28. "The policy gap was noted at the roundtable: 'policy, ethics & equitable access are lagging the tech curve.'"  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

29. "Additionally, leaders might lobby for or contribute to developing education-specific AI guidelines in their region, as a collective approach to these challenges will be more effective than each institution acting alone."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

30. "A collective approach to these challenges will be more effective than each institution acting alone."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

31. "School leaders should lead conversations on academic integrity – e.g. updating honor codes to clarify how AI can or cannot be used on assignments."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

32. "Education leaders could implement AI literacy modules that include ethics, helping students become responsible AI users and creators."  
*AIED 2023*  
https://aied.org/aied2023/

33. "Early adopters may face 'tool fatigue' from trying every new AI gadget, while others feel anxiety about keeping up."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

34. "One takeaway for leaders is to explicitly monitor burnout as a metric."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

35. "There's no value in adopting a new AI tool 'that will be obsolete in 6 months' if it burns out your faculty in the process."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

36. "Acknowledge the unknowns openly and invite input to build trust as you navigate the AI journey together."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

37. "Focus on tools that save time (e.g. automate grading) so teachers can strengthen human relationships with students."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

38. "Involve educators in selecting and evaluating AI – those on the ground will ensure the tech is actually useful in practice."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

39. "Use pilot programs and dual roadmaps to balance innovation and caution."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/

40. "Ensure high-poverty schools in your district receive extra support and funding for AI initiatives, to counteract existing disparities."  
*RAND Study 2023*  
https://www.rand.org/pubs/research_reports/RRA134-25.html

41. "Consider accessibility – e.g. AI tools that work for students with disabilities or multilingual learners – and involve community voices when deploying AI programs."  
*AIED 2023*  
https://aied.org/aied2023/

42. "Require human oversight for critical decisions."  
*U.S. Department of Education AI Report*  
https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf

43. "By leading on policy at the local level, education leaders fill the current vacuum and model responsible AI use."  
*EdTech AI Roundtable 2025*  
https://aied.org/aied2023/
